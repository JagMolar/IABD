{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guía práctica de uso de Hive y Pig\n",
    "\n",
    "En la sesión práctica se presentarán los siguientes contenidos:\n",
    "\n",
    "* Presentación del `dataset` que vamos a utilizar.\n",
    "* Conceptos básicos de Hive.\n",
    "* Resolución de consulta compleja con HQL en el `dataset` de vuelos.\n",
    "* Conceptos básicos de Pig.\n",
    "* Resolución de la misma consulta compleja con Pig Latin en el `dataset` de vuelos.\n",
    "  \n",
    "# Dataset de retrasos en vuelos\n",
    "\n",
    "Vamos a usar [este](https://www.kaggle.com/datasets/tylerx/flights-and-airports-data) de Kaggle\n",
    "para aprender a usar tanto Hive como Pig. Kaggle es un sitio muy popular en ciencia de datos. En este sitio los científicos de datos pueden publicar y compartir sus trabajos. Además también se pueden proponer concursos en los que los participantes compiten en la construcción del mejor modelo para el problema propuesto.\n",
    "\n",
    "El `dataset` contiene información sobre retrasos en vuelos en EEUU. Hay dos ficheros de interés: `airports.csv` y `flights.csv`.\n",
    "\n",
    "El primero tiene información sobre los aeropuertos y consta de los siguientes campos:\n",
    "   * airport_id: identificador del aeropuerto. Numérico, aunque se utilizará un campo `string` en Hive.\n",
    "   * city: ciudad del aeropuerto.\n",
    "   * state: estado del aeropuerto.\n",
    "   * name: nombre del aeropuerto.\n",
    "   \n",
    "El fichero `flights` tiene la siguiente estructura:\n",
    "   * DayofMonth: día del mes del vuelo.\n",
    "   * DayOfWeek: día de la semana del vuelo.\n",
    "   * Carrier: Identificador de la compañía aérea.\n",
    "   * OriginAirportID: Identificador del aeropuerto de origen.\n",
    "   * DestAirportID: Identificador del aeropuerto de destino.\n",
    "   * DepDelay: Minutos de retraso en la salida de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "   * ArrDelay: Minutos de retraso en la llegada de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El directorio `notebooks` contiene el `archiv.zip` con los dos ficheros. Para descargarlo de Kaggle hay que estar registrado y se ha incluido para que no tengas que hacerlo. \n",
    "\n",
    "Extraemos los ficheros que nos interesan. El fichero tiene extensión `zip`. Tenemos que instalar el paquete `unzip` ya que no está disponible en el contenedor.\n",
    "\n",
    "Primero tenemos que actualizar los repositorios de paquetes del contenedor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\u001b[33m\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [991 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1882 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2448 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB][0m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]    \u001b[0m\u001b[33m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB][0m\u001b[33m\u001b[33m\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2011 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2924 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1291 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Fetched 25.1 MB in 4s (6158 kB/s)33m                          \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "190 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "! apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego instalamos el paquete `unzip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 190 not upgraded.\n",
      "Need to get 168 kB of archives.\n",
      "After this operation, 593 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Fetched 168 kB in 0s (576 kB/s)0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 43749 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "! apt install unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los ficheros que nos interesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  archive.zip\n",
      "  inflating: airports.csv            \n",
      "  inflating: flights.csv             \n"
     ]
    }
   ],
   "source": [
    "! unzip -j -o archive.zip  airports.csv flights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el número de líneas y las primeras líneas del fichero de aeropuertos, `airports.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 airports.csv\r\n",
      "airport_id,city,state,name\r",
      "\r\n",
      "10165,Adak Island,AK,Adak\r",
      "\r\n",
      "10299,Anchorage,AK,Ted Stevens Anchorage International\r",
      "\r\n",
      "10304,Aniak,AK,Aniak Airport\r",
      "\r\n",
      "10754,Barrow,AK,Wiley Post/Will Rogers Memorial\r",
      "\r\n",
      "10551,Bethel,AK,Bethel Airport\r",
      "\r\n",
      "10926,Cordova,AK,Merle K Mudhole Smith\r",
      "\r\n",
      "14709,Deadhorse,AK,Deadhorse Airport\r",
      "\r\n",
      "11336,Dillingham,AK,Dillingham Airport\r",
      "\r\n",
      "11630,Fairbanks,AK,Fairbanks International\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l airports.csv && head airports.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el número de líneas y las primeras líneas del fichero de aeropuertos, `flights.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702219 flights.csv\r\n",
      "DayofMonth,DayOfWeek,Carrier,OriginAirportID,DestAirportID,DepDelay,ArrDelay\r",
      "\r\n",
      "19,5,DL,11433,13303,-3,1\r",
      "\r\n",
      "19,5,DL,14869,12478,0,-8\r",
      "\r\n",
      "19,5,DL,14057,14869,-4,-15\r",
      "\r\n",
      "19,5,DL,15016,11433,28,24\r",
      "\r\n",
      "19,5,DL,11193,12892,-6,-11\r",
      "\r\n",
      "19,5,DL,10397,15016,-1,-19\r",
      "\r\n",
      "19,5,DL,15016,10397,0,-1\r",
      "\r\n",
      "19,5,DL,10397,14869,15,24\r",
      "\r\n",
      "19,5,DL,10397,10423,33,34\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l flights.csv && head flights.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, hay 365 aeropuertos (descontada la línea de cabecera) y cerca de tres millones de vuelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiamos los ficheros para hacerlos accesibles en Hadoop. Observa que hemos usado el comando `hdfs` en lugar del comando `hadoop`. Es equivalente hacerlo de una u otra forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 root supergroup      16308 2023-02-07 12:56 /user/root/flights/airports.csv\r\n",
      "-rw-r--r--   3 root supergroup   72088113 2023-02-07 12:56 /user/root/flights/flights.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir -p /user/root/flights\n",
    "! hdfs dfs -put -f ./airports.csv /user/root/flights/\n",
    "! hdfs dfs -put -f ./flights.csv /user/root/flights/\n",
    "! hdfs dfs -ls /user/root/flights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive\n",
    "\n",
    "Ya tenemos instalado un servidor de Hive en nuestro `clúster` Hadoop. Hive es probablemente la herramienta más utilizada en el ecosistema Hadoop. La razón es que utiliza un lenguaje de consultas llamado HQL muy similar a SQL.\n",
    "\n",
    "También hay instalado un cliente de Hive llamado `beeline`. Podemos ejecutar comandos de `beeline` en celdas de Jupyter. Por ejemplo, el siguiente comando se conectaría a Hive y mostraría las bases de datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207125732_edb34956-1100-4df6-833e-6fe783a6cbd1): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207125732_edb34956-1100-4df6-833e-6fe783a6cbd1); Time taken: 1.171 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207125732_edb34956-1100-4df6-833e-6fe783a6cbd1): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207125732_edb34956-1100-4df6-833e-6fe783a6cbd1); Time taken: 0.056 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| default        |\n",
      "+----------------+\n",
      "1 row selected (1.79 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000\" -e \"SHOW DATABASES\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear una nueva base de datos con la siguiente instrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207125808_1bb06737-d49d-41cc-adc1-c93355f0e635): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03'  WITH DBPROPERTIES ('Creada por' = 'Javier P?rez', 'Fecha' = '20/12/22')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207125808_1bb06737-d49d-41cc-adc1-c93355f0e635); Time taken: 0.046 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207125808_1bb06737-d49d-41cc-adc1-c93355f0e635): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03'  WITH DBPROPERTIES ('Creada por' = 'Javier P?rez', 'Fecha' = '20/12/22')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207125808_1bb06737-d49d-41cc-adc1-c93355f0e635); Time taken: 0.232 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.353 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -e \"\\\n",
    "CREATE DATABASE IF NOT EXISTS bda03 \\\n",
    "COMMENT 'Base de datos de la unidad BDA03' \\\n",
    "WITH DBPROPERTIES ('Creada por' = 'Javier Pérez', 'Fecha' = '20/12/22');\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso sería crear las tablas para almacenar los datos de los aeropuertos y de los vuelos. En Hive hay dos tipos de tablas:\n",
    "\n",
    "* Internas: Son manejadas completamente por Hive. Hive copiará los datos de los ficheros usados para crear las tablas en el almacenamiento de Hive. Por defecto usará el directorio: `/user/hive/warehouse/database_name.db/`. Cuando se borre la tabla, Hive borrará tanto los datos como los metadatos.\n",
    "* Externas: Los datos no los maneja Hive. Hive únicamente se ocupa de mantener los metadatos. Para crear una tabla externa hay que añadir la opción EXTERNAL. Las tablas que crearemos en este ejercicio son externas.\n",
    "\n",
    "Para mejorar el rendimiento de Hive, las tablas se pueden particionar por el valor de una columna. Hive creará un directorio por cada valor de la columna particionada. La columna de particionamiento realmente no se almacena como un campo, pero en las consultas se mostrará como si realmente existiera ese campo. \n",
    "\n",
    "Por último, hay que tener en cuenta los tipos de datos que soporta Hive. Puedes consultar los tipos soportados [aquí](https://cwiki.apache.org/confluence/display/hive/languagemanual+types).\n",
    "\n",
    "La tabla que almacenará los datos de los aeropuertos se crea así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207125913_c074cac0-cec9-414f-b4df-c1e8a0e12410): DROP TABLE IF EXISTS airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207125913_c074cac0-cec9-414f-b4df-c1e8a0e12410); Time taken: 0.183 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207125913_c074cac0-cec9-414f-b4df-c1e8a0e12410): DROP TABLE IF EXISTS airports\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207125913_c074cac0-cec9-414f-b4df-c1e8a0e12410); Time taken: 0.13 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.392 seconds)\n",
      "INFO  : Compiling command(queryId=root_20230207125914_03427a64-5dda-4878-ba66-ec55821baa7b): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Javier P?rez', 'Fecha' = '20/12/2022', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207125914_03427a64-5dda-4878-ba66-ec55821baa7b); Time taken: 0.242 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207125914_03427a64-5dda-4878-ba66-ec55821baa7b): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Javier P?rez', 'Fecha' = '20/12/2022', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207125914_03427a64-5dda-4878-ba66-ec55821baa7b); Time taken: 1.074 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (1.355 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS airports; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING) \\\n",
    "COMMENT 'USA Airports' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Javier Pérez', 'Fecha' = '20/12/2022', 'skip.header.line.count'='1');\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias cuestiones que son interesantes comentar en la anterior instrucción:\n",
    "\n",
    "* En primer lugar, observa que hemos añadido el nombre de la base de datos a la cadena de conexión del cliente `beeline`.\n",
    "* El nombre de la tabla creada se llama `airports`.\n",
    "* La tabla es externa. Eso quiere decir que los datos permanecerán en HDFS y no se moverán al almacenamiento interno de Hive.\n",
    "* La tabla consta de cuatro campos de tipo texto y se corresponden con la descripción que hicimos del fichero `airports.csv`.\n",
    "* Se ha especificado que el delimitador de campos es el carácter coma (,).\n",
    "* Por último, se añade una propiedad que permite eliminar la cabecera del fichero `csv`.\n",
    "\n",
    "La tabla de vuelos es similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130028_d4e1e8b9-dd85-4019-938b-0e53623a115d): DROP TABLE IF EXISTS flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130028_d4e1e8b9-dd85-4019-938b-0e53623a115d); Time taken: 0.03 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130028_d4e1e8b9-dd85-4019-938b-0e53623a115d): DROP TABLE IF EXISTS flights\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207130028_d4e1e8b9-dd85-4019-938b-0e53623a115d); Time taken: 0.037 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.147 seconds)\n",
      "INFO  : Compiling command(queryId=root_20230207130029_a1b9e683-2e76-4618-91a2-9fe1611e9c42): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,      depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Javier P?rez', 'Fecha' = '20/12/2022', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130029_a1b9e683-2e76-4618-91a2-9fe1611e9c42); Time taken: 0.03 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130029_a1b9e683-2e76-4618-91a2-9fe1611e9c42): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,      depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Javier P?rez', 'Fecha' = '20/12/2022', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207130029_a1b9e683-2e76-4618-91a2-9fe1611e9c42); Time taken: 0.119 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.176 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS flights; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING, \\\n",
    "    depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT) \\\n",
    "COMMENT 'Flights' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Javier Pérez', 'Fecha' = '20/12/2022', 'skip.header.line.count'='1');\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tabla `flights` se han ajustado los tipos de datos numéricos para que ocupen lo menos posible. El siguiente paso será cargar los datos. Al tratarse tablas externas, Hive no moverá realmente los datos y será un proceso muy rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de cargar los datos tenemos que dar permisos al directorio de HDFS en el que hemos copiado los ficheros `cvs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -chmod 777 /user/root/flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130236_f0bcdde8-9923-4da5-9725-c015f8fec14a): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130236_f0bcdde8-9923-4da5-9725-c015f8fec14a); Time taken: 0.163 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130236_f0bcdde8-9923-4da5-9725-c015f8fec14a): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.airports from hdfs://namenode:8020/user/root/flights/airports.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207130236_f0bcdde8-9923-4da5-9725-c015f8fec14a); Time taken: 1.227 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (1.417 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130252_9aefc2a4-7d19-4e0a-8c05-4cd5cb4e1d99): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130252_9aefc2a4-7d19-4e0a-8c05-4cd5cb4e1d99); Time taken: 0.044 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130252_9aefc2a4-7d19-4e0a-8c05-4cd5cb4e1d99): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.flights from hdfs://namenode:8020/user/root/flights/flights.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20230207130252_9aefc2a4-7d19-4e0a-8c05-4cd5cb4e1d99); Time taken: 0.441 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.543 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has ejecutado las celdas anteriores, habrás comprobado que el proceso de incorporar datos ha sido muy rápido. Esto es así porque, al tratarse de tablas externas, Hive no necesita copiar los datos y porque Hive no realiza comprobaciones de integridad.\n",
    "\n",
    "Ya podemos hacer consultas. Por ejemplo, la siguiente consulta muestra 10 aeropuertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130337_069a1854-b518-49a4-8169-86981d5f3e66): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airports.airportid, type:string, comment:null), FieldSchema(name:airports.city, type:string, comment:null), FieldSchema(name:airports.state, type:string, comment:null), FieldSchema(name:airports.airportname, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130337_069a1854-b518-49a4-8169-86981d5f3e66); Time taken: 2.553 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130337_069a1854-b518-49a4-8169-86981d5f3e66): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20230207130337_069a1854-b518-49a4-8169-86981d5f3e66); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| airports.airportid  | airports.city  | airports.state  |         airports.airportname         |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| 10165               | Adak Island    | AK              | Adak                                 |\n",
      "| 10299               | Anchorage      | AK              | Ted Stevens Anchorage International  |\n",
      "| 10304               | Aniak          | AK              | Aniak Airport                        |\n",
      "| 10754               | Barrow         | AK              | Wiley Post/Will Rogers Memorial      |\n",
      "| 10551               | Bethel         | AK              | Bethel Airport                       |\n",
      "| 10926               | Cordova        | AK              | Merle K Mudhole Smith                |\n",
      "| 14709               | Deadhorse      | AK              | Deadhorse Airport                    |\n",
      "| 11336               | Dillingham     | AK              | Dillingham Airport                   |\n",
      "| 11630               | Fairbanks      | AK              | Fairbanks International              |\n",
      "| 11997               | Gustavus       | AK              | Gustavus Airport                     |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "10 rows selected (2.688 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM airports LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la siguiente muestra 10 vuelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130412_15b8071d-e45c-4ae8-9be3-0b1a5ee56782): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:flights.dayofmonth, type:tinyint, comment:null), FieldSchema(name:flights.dayofweek, type:tinyint, comment:null), FieldSchema(name:flights.carrier, type:string, comment:null), FieldSchema(name:flights.depairportid, type:string, comment:null), FieldSchema(name:flights.arrairportid, type:string, comment:null), FieldSchema(name:flights.depdelay, type:smallint, comment:null), FieldSchema(name:flights.arrdelay, type:smallint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130412_15b8071d-e45c-4ae8-9be3-0b1a5ee56782); Time taken: 0.188 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130412_15b8071d-e45c-4ae8-9be3-0b1a5ee56782): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20230207130412_15b8071d-e45c-4ae8-9be3-0b1a5ee56782); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| flights.dayofmonth  | flights.dayofweek  | flights.carrier  | flights.depairportid  | flights.arrairportid  | flights.depdelay  | flights.arrdelay  |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| 19                  | 5                  | DL               | 11433                 | 13303                 | -3                | 1                 |\n",
      "| 19                  | 5                  | DL               | 14869                 | 12478                 | 0                 | -8                |\n",
      "| 19                  | 5                  | DL               | 14057                 | 14869                 | -4                | -15               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 11433                 | 28                | 24                |\n",
      "| 19                  | 5                  | DL               | 11193                 | 12892                 | -6                | -11               |\n",
      "| 19                  | 5                  | DL               | 10397                 | 15016                 | -1                | -19               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 10397                 | 0                 | -1                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 14869                 | 15                | 24                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 10423                 | 33                | 34                |\n",
      "| 19                  | 5                  | DL               | 11278                 | 10397                 | 323               | 322               |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "10 rows selected (0.544 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM flights LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer una consulta para aprender como usar Hive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta en Hive: Nombre de los 5 aeropuertos con mayor número de operaciones (llegadas y salidas).\n",
    "\n",
    "Empezamos mostrando las salidas que se producen agrupadas por aeropuerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130541_d5772487-fc84-4680-bce1-d1e1b9d48668): SELECT depairportid as airportid, count(*) AS flights FROM flights GROUP BY depairportid  ORDER BY flights DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airportid, type:string, comment:null), FieldSchema(name:flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130541_d5772487-fc84-4680-bce1-d1e1b9d48668); Time taken: 2.06 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130541_d5772487-fc84-4680-bce1-d1e1b9d48668): SELECT depairportid as airportid, count(*) AS flights FROM flights GROUP BY depairportid  ORDER BY flights DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20230207130541_d5772487-fc84-4680-bce1-d1e1b9d48668\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0001\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0001/\n",
      "INFO  : Starting Job = job_1675770379551_0001, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0001/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0001\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:06:28,304 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:07:11,904 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.79 sec\n",
      "INFO  : 2023-02-07 13:07:26,499 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.9 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 19 seconds 900 msec\n",
      "INFO  : Ended Job = job_1675770379551_0001\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0002\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0002/\n",
      "INFO  : Starting Job = job_1675770379551_0002, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0002/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0002\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:07:41,428 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:07:51,766 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.56 sec\n",
      "INFO  : 2023-02-07 13:08:00,085 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.53 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 6 seconds 530 msec\n",
      "INFO  : Ended Job = job_1675770379551_0002\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.9 sec   HDFS Read: 72101674 HDFS Write: 1927 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.53 sec   HDFS Read: 9536 HDFS Write: 211 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 26 seconds 430 msec\n",
      "INFO  : Completed executing command(queryId=root_20230207130541_d5772487-fc84-4680-bce1-d1e1b9d48668); Time taken: 139.612 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+------------+----------+\n",
      "| airportid  | flights  |\n",
      "+------------+----------+\n",
      "| 10397      | 148563   |\n",
      "| 13930      | 127195   |\n",
      "| 12892      | 117714   |\n",
      "| 11298      | 104270   |\n",
      "| 11292      | 97259    |\n",
      "+------------+----------+\n",
      "5 rows selected (141.955 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT depairportid as airportid, count(*) AS flights FROM flights GROUP BY depairportid \\\n",
    "ORDER BY flights DESC LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer lo mismo con las llegadas y unir las dos consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207130822_f498a4c1-1151-4cdf-bf20-934cd1f0c7de): SELECT airportid, COUNT(*) as flights FROM (      SELECT depairportid as airportid FROM flights      UNION ALL      SELECT arrairportid as airportid FROM flights  ) f GROUP BY airportid  ORDER BY flights DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airportid, type:string, comment:null), FieldSchema(name:flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207130822_f498a4c1-1151-4cdf-bf20-934cd1f0c7de); Time taken: 0.586 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207130822_f498a4c1-1151-4cdf-bf20-934cd1f0c7de): SELECT airportid, COUNT(*) as flights FROM (      SELECT depairportid as airportid FROM flights      UNION ALL      SELECT arrairportid as airportid FROM flights  ) f GROUP BY airportid  ORDER BY flights DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20230207130822_f498a4c1-1151-4cdf-bf20-934cd1f0c7de\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0003\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0003/\n",
      "INFO  : Starting Job = job_1675770379551_0003, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0003/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0003\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:08:33,438 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:08:49,395 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.53 sec\n",
      "INFO  : 2023-02-07 13:08:55,662 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 15.26 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 15 seconds 260 msec\n",
      "INFO  : Ended Job = job_1675770379551_0003\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0004\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0004/\n",
      "INFO  : Starting Job = job_1675770379551_0004, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0004/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0004\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:09:07,176 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:09:15,498 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.11 sec\n",
      "INFO  : 2023-02-07 13:09:23,790 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.21 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 6 seconds 210 msec\n",
      "INFO  : Ended Job = job_1675770379551_0004\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 15.26 sec   HDFS Read: 72098141 HDFS Write: 1946 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.21 sec   HDFS Read: 9559 HDFS Write: 212 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 21 seconds 470 msec\n",
      "INFO  : Completed executing command(queryId=root_20230207130822_f498a4c1-1151-4cdf-bf20-934cd1f0c7de); Time taken: 62.474 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+------------+----------+\n",
      "| airportid  | flights  |\n",
      "+------------+----------+\n",
      "| 10397      | 297087   |\n",
      "| 13930      | 254536   |\n",
      "| 12892      | 235988   |\n",
      "| 11298      | 208209   |\n",
      "| 11292      | 194178   |\n",
      "+------------+----------+\n",
      "5 rows selected (63.198 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT airportid, COUNT(*) as flights FROM ( \\\n",
    "    SELECT depairportid as airportid FROM flights \\\n",
    "    UNION ALL \\\n",
    "    SELECT arrairportid as airportid FROM flights \\\n",
    ") f GROUP BY airportid \\\n",
    "ORDER BY flights DESC LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los códigos de los 5 aeropuertos con más operaciones. Lo único que queda por hacer es obtener el nombre del aeropuerto. Para ello hacemos un `join` con la tabla `airports`. Para hacerlo más inteligible creamos una tabla temporal con los resultados anteriores y el `join` lo hacemos sobre esta tabla temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20230207131059_00d2ffe0-70fd-4189-8636-737ada0bc72b): CREATE TEMPORARY TABLE airport_operations AS  SELECT airportid, COUNT(*) as flights FROM (      SELECT depairportid as airportid FROM flights      UNION ALL      SELECT arrairportid as airportid FROM flights  ) f GROUP BY airportid  ORDER BY flights DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airportid, type:string, comment:null), FieldSchema(name:flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207131059_00d2ffe0-70fd-4189-8636-737ada0bc72b); Time taken: 0.329 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207131059_00d2ffe0-70fd-4189-8636-737ada0bc72b): CREATE TEMPORARY TABLE airport_operations AS  SELECT airportid, COUNT(*) as flights FROM (      SELECT depairportid as airportid FROM flights      UNION ALL      SELECT arrairportid as airportid FROM flights  ) f GROUP BY airportid  ORDER BY flights DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20230207131059_00d2ffe0-70fd-4189-8636-737ada0bc72b\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0005\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0005/\n",
      "INFO  : Starting Job = job_1675770379551_0005, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0005/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0005\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:11:08,867 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:11:21,400 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.7 sec\n",
      "INFO  : 2023-02-07 13:11:28,669 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.7 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 9 seconds 880 msec\n",
      "INFO  : Ended Job = job_1675770379551_0005\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0006\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0006/\n",
      "INFO  : Starting Job = job_1675770379551_0006, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0006/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0006\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:11:41,570 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:11:50,460 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.92 sec\n",
      "INFO  : 2023-02-07 13:11:59,811 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.9 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 6 seconds 900 msec\n",
      "INFO  : Ended Job = job_1675770379551_0006\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Moving data to directory hdfs://namenode:8020/tmp/hive/anonymous/5efd620d-cdb6-43fb-8ead-768a65fb8078/_tmp_space.db/d504578c-9c10-4163-974f-21665b180c60 from hdfs://namenode:8020/tmp/hive/anonymous/5efd620d-cdb6-43fb-8ead-768a65fb8078/_tmp_space.db/d504578c-9c10-4163-974f-21665b180c60/.hive-staging_hive_2023-02-07_13-10-59_516_7721255476388350146-2/-ext-10002\n",
      "INFO  : Starting task [Stage-5:DDL] in serial mode\n",
      "INFO  : Starting task [Stage-3:STATS] in serial mode\n",
      "No rows affected (61.687 seconds)\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 9.88 sec   HDFS Read: 72098175 HDFS Write: 1946 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.9 sec   HDFS Read: 9602 HDFS Write: 145 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 16 seconds 780 msec\n",
      "INFO  : Completed executing command(queryId=root_20230207131059_00d2ffe0-70fd-4189-8636-737ada0bc72b); Time taken: 61.335 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Compiling command(queryId=root_20230207131201_2ffd0c2b-170c-4755-a137-a26cd3f042f1): SELECT airportname, flights  FROM airport_operations JOIN airports ON airport_operations.airportid = airports.airportid  ORDER BY flights DESC\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airportname, type:string, comment:null), FieldSchema(name:flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20230207131201_2ffd0c2b-170c-4755-a137-a26cd3f042f1); Time taken: 0.495 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20230207131201_2ffd0c2b-170c-4755-a137-a26cd3f042f1): SELECT airportname, flights  FROM airport_operations JOIN airports ON airport_operations.airportid = airports.airportid  ORDER BY flights DESC\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20230207131201_2ffd0c2b-170c-4755-a137-a26cd3f042f1\n",
      "INFO  : Total jobs = 1\n",
      "INFO  : Starting task [Stage-5:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 1\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1675770379551_0007\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1675770379551_0007/\n",
      "INFO  : Starting Job = job_1675770379551_0007, Tracking URL = http://yarnmaster:8088/proxy/application_1675770379551_0007/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1675770379551_0007\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2023-02-07 13:12:19,079 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2023-02-07 13:12:29,441 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.64 sec\n",
      "INFO  : 2023-02-07 13:12:35,660 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 8.77 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 8 seconds 770 msec\n",
      "INFO  : Ended Job = job_1675770379551_0007\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 8.77 sec   HDFS Read: 33220 HDFS Write: 331 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 8 seconds 770 msec\n",
      "INFO  : Completed executing command(queryId=root_20230207131201_2ffd0c2b-170c-4755-a137-a26cd3f042f1); Time taken: 35.061 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+----------+\r\n",
      "|                airportname                | flights  |\r\n",
      "+-------------------------------------------+----------+\r\n",
      "| Hartsfield-Jackson Atlanta International  | 297087   |\r\n",
      "| Chicago O'Hare International              | 254536   |\r\n",
      "| Los Angeles International                 | 235988   |\r\n",
      "| Dallas/Fort Worth International           | 208209   |\r\n",
      "| Denver International                      | 194178   |\r\n",
      "+-------------------------------------------+----------+\r\n",
      "5 rows selected (35.625 seconds)\r\n",
      "Beeline version 3.1.2 by Apache Hive\r\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\r\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "CREATE TEMPORARY TABLE airport_operations AS \\\n",
    "SELECT airportid, COUNT(*) as flights FROM ( \\\n",
    "    SELECT depairportid as airportid FROM flights \\\n",
    "    UNION ALL \\\n",
    "    SELECT arrairportid as airportid FROM flights \\\n",
    ") f GROUP BY airportid \\\n",
    "ORDER BY flights DESC LIMIT 5; \\\n",
    "\\\n",
    "SELECT airportname, flights \\\n",
    "FROM airport_operations JOIN airports ON airport_operations.airportid = airports.airportid \\\n",
    "ORDER BY flights DESC;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pig\n",
    "\n",
    "Como en el caso de Hive, también tenemos instalado el cliente de Pig en nuestro `cluster` de Hadoop (Pig no tiene servidor). Mientras que Hive es una herramienta pensada para trabajar sobre información estructurada de forma declarativa, Pig puede trabajar sobre información semiestructurada y es una mezcla de programación declarativa y procedimental. Es, por lo tanto, más flexible que Hive. Pig usa un lenguaje de consultas llamado Pig Latin.\n",
    "\n",
    "Al igual que Hive, Pig tiene sus propios tipos de datos. Puedes consultarlos [aquí](https://pig.apache.org/docs/latest/basic.html#data-types).\n",
    "\n",
    "Para ejecutar Pig en Jupyter debemos crear un `script` y ejecutarlo con Pig.\n",
    "\n",
    "Por ejemplo, para leer los ficheros `airports.csv` y `flights.csv` escribimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "-- resgistramos la librería PiggyBank para poder usar la función de carga CSVExcelStorage.\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "/*\n",
    "Leemos el fichero de airports.csv.\n",
    "\n",
    "Usamos el loader CSVExcelStorage indicando el delimitador (,) y que se debe excluir la cabecera.\n",
    "*/\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "\n",
    "-- Probamos que podemos recuperar datos.\n",
    "      \n",
    "-- Nos quedamos con 10 aeropuertos\n",
    "AIRPORTS_10 = LIMIT AIRPORTS 10;\n",
    "\n",
    "-- Mostramos 10 aeropuertos\n",
    "DUMP AIRPORTS_10;\n",
    "\n",
    "-- Hacemos lo mismo con los vuelos\n",
    "FLIGHTS_10 = LIMIT FLIGHTS 10;\n",
    "DUMP FLIGHTS_10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:04:11,936 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2023-02-07 14:04:11,940 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2023-02-07 14:04:12,065 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2023-02-07 14:04:12,065 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/pig_1675775052058.log\n",
      "2023-02-07 14:04:12,102 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2023-02-07 14:04:12,350 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2023-02-07 14:04:12,466 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:04:12,468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2023-02-07 14:04:12,550 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-d9698246-5c7a-4119-a50f-c8449344d320\n",
      "2023-02-07 14:04:12,550 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2023-02-07 14:04:13,508 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2023-02-07 14:04:13,594 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2023-02-07 14:04:13,692 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:04:13,783 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:04:13,783 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:04:13,976 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:04:14,000 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:04:14,007 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:04:14,086 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1201045018/tmp224203213\n",
      "2023-02-07 14:04:14,095 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:04:14,102 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:04:14,102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(10165,Adak Island,AK,Adak)\n",
      "(10299,Anchorage,AK,Ted Stevens Anchorage International)\n",
      "(10304,Aniak,AK,Aniak Airport)\n",
      "(10754,Barrow,AK,Wiley Post/Will Rogers Memorial)\n",
      "(10551,Bethel,AK,Bethel Airport)\n",
      "(10926,Cordova,AK,Merle K Mudhole Smith)\n",
      "(14709,Deadhorse,AK,Deadhorse Airport)\n",
      "(11336,Dillingham,AK,Dillingham Airport)\n",
      "(11630,Fairbanks,AK,Fairbanks International)\n",
      "(11997,Gustavus,AK,Gustavus Airport)\n",
      "2023-02-07 14:04:14,212 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2023-02-07 14:04:14,233 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:04:14,234 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2023-02-07 14:04:14,266 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:04:14,266 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:04:14,290 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:04:14,298 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:04:14,298 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:04:14,316 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1201045018/tmp-1611365136\n",
      "2023-02-07 14:04:14,320 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:04:14,324 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:04:14,324 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(19,5,DL,11433,13303,-3,1)\n",
      "(19,5,DL,14869,12478,0,-8)\n",
      "(19,5,DL,14057,14869,-4,-15)\n",
      "(19,5,DL,15016,11433,28,24)\n",
      "(19,5,DL,11193,12892,-6,-11)\n",
      "(19,5,DL,10397,15016,-1,-19)\n",
      "(19,5,DL,15016,10397,0,-1)\n",
      "(19,5,DL,10397,14869,15,24)\n",
      "(19,5,DL,10397,10423,33,34)\n",
      "(19,5,DL,11278,10397,323,322)\n",
      "2023-02-07 14:04:14,427 [main] INFO  org.apache.pig.Main - Pig script completed in 2 seconds and 835 milliseconds (2835 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa varias cuestiones interesantes:\n",
    "\n",
    "* Los `scripts` de Pig admiten dos tipos de comentarios: orientados a línea y orientados a bloque.\n",
    "* Hemos tenido que registrar la librería `piggybank.jar` para poder usar el `loader` `CSVExcelStorage`. Este `loader` es más potente que el que se usa por defecto en Pig y que se llama `PigStorage`. Concretamente en este ejemplo lo hemos usado para eliminar las líneas de cabecera de los ficheros `csv`.\n",
    "* Cada comando de Pig Latin es atómico (hace una sola operación) y no se pueden componer, con lo que hay que ir haciendo asignaciones sucesivas. Es habitual que las asignaciones se hagan sobre la misma variable sobrescribiéndola. Desde mi punto de vista esa técnica resta claridad y prefiero ir creando nuevas variables según avanza el proceso.\n",
    "* Al ejecutar Pig podemos pasar variables que son accesibles desde el `script`.\n",
    "* He tenido que ejecutar Pig en modo local con la opción `-x local` ya que mi equipo se queda sin memoria si trato de ejecutarlo en Hadoop. Puedes probar a cambiar esta opción y probar si tu equipo soporta la ejecución en el `clúster` de Hadoop.\n",
    "* Observa que la salida del `script` muestra 10 aeropuertos y 10 vuelos con una estructura de datos de tupla. La tupla es uno de los tipos complejos que soporta Pig. Los otros dos tipos complejos son `map` y `bag`. Usaremos el último más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta en Pig: Nombre de los 5 aeropuertos con mayor número de operaciones (llegadas y salidas).\n",
    "\n",
    "Vamos a resolver la misma consulta que hicimos en Hive pero esta vez utilizando Pig. Seguimos una estrategia parecida a la de Hive: unimos las salidas y las llegadas y agrupamos por aeropuerto. El `script` siguiente está incompleto ya que tan sólo llega hasta hacer la agrupación, pero falta el `join` con aeropuertos para obtener el nombre. Se ha hecho así para explicar que la relación creada con GROUP no tiene a misma estructura que la equivalente con GROUP BY en Hive. Más adelante resolveremos la consulta completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "-- resgistramos la librería PiggyBank para poder usar la función de carga CSVExcelStorage.\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "/*\n",
    "Leemos el fichero de airports.csv.\n",
    "\n",
    "Usamos el loader CSVExcelStorage indicando el delimitador (,) y que se debe excluir la cabecera.\n",
    "*/\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "\n",
    "/*\n",
    "    FOREACH ... GENERATE es similar al SELECT de SQL\n",
    "*/\n",
    "DEPARTURES = FOREACH FLIGHTS GENERATE depairportid AS airportid;\n",
    "ARRIVES    = FOREACH FLIGHTS GENERATE arrairportid AS airportid;\n",
    "\n",
    "OPERATIONS = UNION DEPARTURES, ARRIVES;\n",
    "\n",
    "TOTAL_OPERATIONS = GROUP OPERATIONS BY airportid;\n",
    "\n",
    "-- Mostramos el esquema de la relación para que se entienda cómo funciona GROUP\n",
    "DESCRIBE TOTAL_OPERATIONS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:08:24,703 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2023-02-07 14:08:24,704 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2023-02-07 14:08:24,805 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2023-02-07 14:08:24,805 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/pig_1675775304799.log\n",
      "2023-02-07 14:08:24,850 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2023-02-07 14:08:25,249 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2023-02-07 14:08:25,520 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:08:25,523 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2023-02-07 14:08:25,593 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-5f32f7c8-7d2d-4d04-ad9f-e65e3279f59d\n",
      "2023-02-07 14:08:25,593 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "TOTAL_OPERATIONS: {group: chararray,OPERATIONS: {(airportid: chararray)}}\n",
      "2023-02-07 14:08:26,760 [main] INFO  org.apache.pig.Main - Pig script completed in 2 seconds and 344 milliseconds (2344 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa varias cosas:\n",
    "\n",
    "* La consulta ha tardado muy poco tiempo. Esto es debido a que Pig no realiza la consulta hasta que no se muestren los datos por pantalla o se almacenen en un fichero.\n",
    "* La relación TOTAL_OPERATIONS está formada por tuplas con dos campos: `group` y OPERATIONS. El nombre `group` lo ha asignado PIG y contiene el valor del campo por el que hemos agrupado (en este caso el código de aeropuerto). OPERATIONS es un `bag` (lista de tuplas) con las tuplas agrupadas. Es decir, que si mostráramos los datos agrupados, veríamos tuplas con datos similares a estos:\n",
    "    (1, (1,1,1,1,1)), donde 1 sería el código de aeropuerto.\n",
    "    \n",
    "Continuamos con el `script` contando y renombrando campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "-- resgistramos la librería PiggyBank para poder usar la función de carga CSVExcelStorage.\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "/*\n",
    "Leemos el fichero de airports.csv.\n",
    "\n",
    "Usamos el loader CSVExcelStorage indicando el delimitador (,) y que se debe excluir la cabecera.\n",
    "*/\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "\n",
    "/*\n",
    "    FOREACH ... GENERATE es similar al SELECT de SQL\n",
    "*/\n",
    "DEPARTURES = FOREACH FLIGHTS GENERATE depairportid AS airportid;\n",
    "ARRIVES    = FOREACH FLIGHTS GENERATE arrairportid AS airportid;\n",
    "\n",
    "OPERATIONS = UNION DEPARTURES, ARRIVES;\n",
    "\n",
    "TOTAL_OPERATIONS = GROUP OPERATIONS BY airportid;\n",
    "\n",
    "-- Mostramos el esquema de la relación para que se entienda cómo funciona GROUP\n",
    "DESCRIBE TOTAL_OPERATIONS;\n",
    "\n",
    "-- Renombramos campos y contamos vuelos\n",
    "TOTAL_OPERATIONS = FOREACH TOTAL_OPERATIONS GENERATE group AS airportid, COUNT(OPERATIONS) AS flights;\n",
    "\n",
    "-- Ordenamos de forma descendente por vuelos\n",
    "TOTAL_OPERATIONS = ORDER TOTAL_OPERATIONS BY flights DESC;\n",
    "\n",
    "-- Limitamos a 5 aeropuertos\n",
    "TOP_TOTAL_OPERATIONS = LIMIT TOTAL_OPERATIONS 5;\n",
    "\n",
    "-- Hacemos un join con la relación de aeropuertos para obtener el nombre\n",
    "TOP_TOTAL_OPERATIONS = JOIN TOP_TOTAL_OPERATIONS BY airportid, AIRPORTS BY airportid;\n",
    "\n",
    "DESCRIBE TOP_TOTAL_OPERATIONS;\n",
    "\n",
    "-- Seleccionamos los campos que nos interesan\n",
    "TOP_TOTAL_OPERATIONS = FOREACH TOP_TOTAL_OPERATIONS GENERATE airportname, flights;\n",
    "\n",
    "-- Volvemos a ordenar por el número de vuelos\n",
    "TOP_TOTAL_OPERATIONS = ORDER TOP_TOTAL_OPERATIONS BY flights DESC;\n",
    "\n",
    "DUMP TOP_TOTAL_OPERATIONS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:12:43,283 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2023-02-07 14:12:43,284 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2023-02-07 14:12:43,349 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2023-02-07 14:12:43,349 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/pig_1675775563347.log\n",
      "2023-02-07 14:12:43,364 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2023-02-07 14:12:43,517 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2023-02-07 14:12:43,598 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:12:43,600 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2023-02-07 14:12:43,640 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-24f99963-96eb-4912-ad20-04d390ba14db\n",
      "2023-02-07 14:12:43,640 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "TOTAL_OPERATIONS: {group: chararray,OPERATIONS: {(airportid: chararray)}}\n",
      "TOP_TOTAL_OPERATIONS: {TOP_TOTAL_OPERATIONS::airportid: chararray,TOP_TOTAL_OPERATIONS::flights: long,AIRPORTS::airportid: chararray,AIRPORTS::city: chararray,AIRPORTS::state: chararray,AIRPORTS::airportname: chararray}\n",
      "2023-02-07 14:12:44,911 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,LIMIT,UNION\n",
      "2023-02-07 14:12:44,983 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2023-02-07 14:12:45,013 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for AIRPORTS: $1, $2\n",
      "2023-02-07 14:12:45,015 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for FLIGHTS: $0, $1, $2, $5, $6\n",
      "2023-02-07 14:12:45,078 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:12:45,167 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2023-02-07 14:12:45,195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2023-02-07 14:12:45,229 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-74\n",
      "2023-02-07 14:12:45,229 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-108\n",
      "2023-02-07 14:12:45,233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer - Rewrite: POPackage->POForEach to POPackage(JoinPackager)\n",
      "2023-02-07 14:12:45,252 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 8\n",
      "2023-02-07 14:12:45,253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 1 diamond splitter.\n",
      "2023-02-07 14:12:45,253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 1 out of total 2 MR operators.\n",
      "2023-02-07 14:12:45,253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 7\n",
      "2023-02-07 14:12:45,478 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2023-02-07 14:12:45,613 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2023-02-07 14:12:45,613 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2023-02-07 14:12:45,645 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:12:45,654 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:12:45,654 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:12:45,657 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2023-02-07 14:12:45,660 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:12:45,662 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2023-02-07 14:12:45,681 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=144176226\n",
      "2023-02-07 14:12:45,681 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:12:45,681 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:12:45,692 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2023-02-07 14:12:45,708 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2023-02-07 14:12:45,708 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2023-02-07 14:12:45,708 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1675775565707-0\n",
      "2023-02-07 14:12:45,811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:12:45,828 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:12:45,865 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2023-02-07 14:12:45,939 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:12:45,960 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:12:45,960 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:12:45,979 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2023-02-07 14:12:45,992 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:12:45,992 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:12:45,993 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:12:46,038 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:6\n",
      "2023-02-07 14:12:46,249 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1252471141_0001\n",
      "2023-02-07 14:12:46,249 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2023-02-07 14:12:46,409 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:12:46,413 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:12:46,414 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1252471141_0001\n",
      "2023-02-07 14:12:46,414 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ARRIVES,DEPARTURES,FLIGHTS,OPERATIONS,TOTAL_OPERATIONS\n",
      "2023-02-07 14:12:46,414 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:12:46,422 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2023-02-07 14:12:46,422 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1252471141_0001]\n",
      "2023-02-07 14:12:46,455 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:12:46,456 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:12:46,456 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:12:46,462 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:12:46,462 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:12:46,463 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:12:46,528 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:12:46,529 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_m_000000_0\n",
      "2023-02-07 14:12:46,579 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:12:46,579 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:12:46,614 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:12:46,624 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:12:46,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:0+33554432\n",
      "2023-02-07 14:12:46,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:12:46,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:12:46,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:12:46,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:12:46,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:12:46,733 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:12:46,763 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:12:46,765 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2023-02-07 14:12:46,782 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:12:55,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:12:55,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:12:55,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:12:55,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 16347305; bufvoid = 104857600\n",
      "2023-02-07 14:12:55,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 21184460(84737840); length = 5029937/6553600\n",
      "2023-02-07 14:12:55,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:12:56,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:12:56,296 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:12:56,298 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:12:56,298 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_m_000000_0' done.\n",
      "2023-02-07 14:12:56,307 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_m_000000_0: Counters: 19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33560855\n",
      "\t\tFILE: Number of bytes written=635437\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=1257485\n",
      "\t\tMap output bytes=16347305\n",
      "\t\tMap output materialized bytes=1216\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=1257485\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=61\n",
      "\t\tTotal committed heap usage (bytes)=492306432\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_flights.csv=1257485\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:12:56,307 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_m_000000_0\n",
      "2023-02-07 14:12:56,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_m_000001_0\n",
      "2023-02-07 14:12:56,313 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:12:56,313 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:12:56,313 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:12:56,315 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:12:56,318 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:33554432+33554432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:12:56,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:12:56,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:12:56,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:12:56,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:12:56,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:12:56,332 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:12:56,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:12:56,350 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:12:56,354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:12:56,427 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 7% complete\n",
      "2023-02-07 14:12:56,428 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1252471141_0001]\n",
      "2023-02-07 14:13:07,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:07,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:07,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:07,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 16365297; bufvoid = 104857600\n",
      "2023-02-07 14:13:07,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 21178924(84715696); length = 5035473/6553600\n",
      "2023-02-07 14:13:08,183 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:08,185 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_m_000001_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:08,187 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:08,187 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_m_000001_0' done.\n",
      "2023-02-07 14:13:08,187 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_m_000001_0: Counters: 19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67121578\n",
      "\t\tFILE: Number of bytes written=636685\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=1258869\n",
      "\t\tMap output bytes=16365297\n",
      "\t\tMap output materialized bytes=1216\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=1258869\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=1714\n",
      "\t\tTotal committed heap usage (bytes)=601882624\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_flights.csv=1258869\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:08,187 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_m_000001_0\n",
      "2023-02-07 14:13:08,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_m_000002_0\n",
      "2023-02-07 14:13:08,193 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:08,193 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:08,193 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:08,194 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:08,197 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:0+33554432\n",
      "2023-02-07 14:13:08,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:08,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:08,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:08,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:08,214 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:08,216 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:08,230 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:08,230 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:08,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:13:15,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:15,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:15,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:15,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 16347305; bufvoid = 104857600\n",
      "2023-02-07 14:13:15,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 21184460(84737840); length = 5029937/6553600\n",
      "2023-02-07 14:13:16,344 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:16,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_m_000002_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:16,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:16,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_m_000002_0' done.\n",
      "2023-02-07 14:13:16,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_m_000002_0: Counters: 19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=100681789\n",
      "\t\tFILE: Number of bytes written=637933\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=1257485\n",
      "\t\tMap output bytes=16347305\n",
      "\t\tMap output materialized bytes=1216\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=1257485\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=244\n",
      "\t\tTotal committed heap usage (bytes)=645922816\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_flights.csv=1257485\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:16,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_m_000002_0\n",
      "2023-02-07 14:13:16,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_m_000003_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:16,354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:16,354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:16,354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:16,355 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:16,361 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:33554432+33554432\n",
      "2023-02-07 14:13:16,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:16,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:16,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:16,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:16,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:16,376 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:16,393 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:16,393 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:16,396 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:13:23,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:23,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:23,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:23,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 16365297; bufvoid = 104857600\n",
      "2023-02-07 14:13:23,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 21178924(84715696); length = 5035473/6553600\n",
      "2023-02-07 14:13:24,045 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:24,047 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_m_000003_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:24,048 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:24,048 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_m_000003_0' done.\n",
      "2023-02-07 14:13:24,048 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_m_000003_0: Counters: 19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=134241488\n",
      "\t\tFILE: Number of bytes written=639181\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=1258869\n",
      "\t\tMap output bytes=16365297\n",
      "\t\tMap output materialized bytes=1216\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=1258869\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=148\n",
      "\t\tTotal committed heap usage (bytes)=680001536\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_flights.csv=1258869\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:24,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_m_000003_0\n",
      "2023-02-07 14:13:24,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_m_000004_0\n",
      "2023-02-07 14:13:24,054 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:24,054 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:24,055 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:24,057 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:24,060 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:67108864+4979249\n",
      "2023-02-07 14:13:24,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:24,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:24,076 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:24,076 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:24,076 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:24,077 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:24,093 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:24,093 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:24,097 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:13:25,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:25,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:25,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:25,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2416232; bufvoid = 104857600\n",
      "2023-02-07 14:13:25,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25470944(101883776); length = 743453/6553600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:25,476 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:25,478 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_m_000004_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:25,479 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:25,479 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_m_000004_0' done.\n",
      "2023-02-07 14:13:25,480 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_m_000004_0: Counters: 19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=139221908\n",
      "\t\tFILE: Number of bytes written=640409\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=185864\n",
      "\t\tMap output bytes=2416232\n",
      "\t\tMap output materialized bytes=1196\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=185864\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=105\n",
      "\t\tTotal committed heap usage (bytes)=695205888\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_flights.csv=185864\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:25,480 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_m_000004_0\n",
      "2023-02-07 14:13:25,480 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_m_000005_0\n",
      "2023-02-07 14:13:25,484 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:25,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:25,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:25,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:25,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:67108864+4979249\n",
      "2023-02-07 14:13:25,501 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:25,501 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:25,501 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:25,501 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:25,501 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:25,503 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:25,518 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:25,518 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:25,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:13:26,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:26,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:26,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:26,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2416232; bufvoid = 104857600\n",
      "2023-02-07 14:13:26,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25470944(101883776); length = 743453/6553600\n",
      "2023-02-07 14:13:26,822 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:26,824 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_m_000005_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:26,826 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:26,826 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_m_000005_0' done.\n",
      "2023-02-07 14:13:26,826 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_m_000005_0: Counters: 19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144201816\n",
      "\t\tFILE: Number of bytes written=641637\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=185864\n",
      "\t\tMap output bytes=2416232\n",
      "\t\tMap output materialized bytes=1196\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=185864\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=114\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_flights.csv=185864\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:26,826 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_m_000005_0\n",
      "2023-02-07 14:13:26,826 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:26,831 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:26,833 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1252471141_0001_r_000000_0\n",
      "2023-02-07 14:13:26,850 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:26,850 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:26,852 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:26,859 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20b5ba18\n",
      "2023-02-07 14:13:26,863 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:26,891 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:26,897 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1252471141_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:26,931 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1252471141_0001_m_000001_0 decomp: 1212 len: 1216 to MEMORY\n",
      "2023-02-07 14:13:26,935 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1212 bytes from map-output for attempt_local1252471141_0001_m_000001_0\n",
      "2023-02-07 14:13:26,938 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1212, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1212\n",
      "2023-02-07 14:13:26,943 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1252471141_0001_m_000005_0 decomp: 1192 len: 1196 to MEMORY\n",
      "2023-02-07 14:13:26,944 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1192 bytes from map-output for attempt_local1252471141_0001_m_000005_0\n",
      "2023-02-07 14:13:26,944 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1192, inMemoryMapOutputs.size() -> 2, commitMemory -> 1212, usedMemory ->2404\n",
      "2023-02-07 14:13:26,945 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1252471141_0001_m_000002_0 decomp: 1212 len: 1216 to MEMORY\n",
      "2023-02-07 14:13:26,946 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1212 bytes from map-output for attempt_local1252471141_0001_m_000002_0\n",
      "2023-02-07 14:13:26,946 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1212, inMemoryMapOutputs.size() -> 3, commitMemory -> 2404, usedMemory ->3616\n",
      "2023-02-07 14:13:26,947 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1252471141_0001_m_000003_0 decomp: 1212 len: 1216 to MEMORY\n",
      "2023-02-07 14:13:26,948 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1212 bytes from map-output for attempt_local1252471141_0001_m_000003_0\n",
      "2023-02-07 14:13:26,948 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1212, inMemoryMapOutputs.size() -> 4, commitMemory -> 3616, usedMemory ->4828\n",
      "2023-02-07 14:13:26,949 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1252471141_0001_m_000000_0 decomp: 1212 len: 1216 to MEMORY\n",
      "2023-02-07 14:13:26,950 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1212 bytes from map-output for attempt_local1252471141_0001_m_000000_0\n",
      "2023-02-07 14:13:26,950 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1212, inMemoryMapOutputs.size() -> 5, commitMemory -> 4828, usedMemory ->6040\n",
      "2023-02-07 14:13:26,950 [Readahead Thread #0] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:419)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:296)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:220)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2023-02-07 14:13:26,950 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1252471141_0001_m_000004_0 decomp: 1192 len: 1196 to MEMORY\n",
      "2023-02-07 14:13:26,954 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1192 bytes from map-output for attempt_local1252471141_0001_m_000004_0\n",
      "2023-02-07 14:13:26,954 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1192, inMemoryMapOutputs.size() -> 6, commitMemory -> 6040, usedMemory ->7232\n",
      "2023-02-07 14:13:26,955 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:26,956 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 6 / 6 copied.\n",
      "2023-02-07 14:13:26,956 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 6 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:26,965 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 6 sorted segments\n",
      "2023-02-07 14:13:26,965 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 6 segments left of total size: 7172 bytes\n",
      "2023-02-07 14:13:26,970 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 6 segments, 7232 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:26,970 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7226 bytes from disk\n",
      "2023-02-07 14:13:26,971 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:26,971 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:26,971 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7212 bytes\n",
      "2023-02-07 14:13:26,975 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 6 / 6 copied.\n",
      "2023-02-07 14:13:26,983 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:26,983 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:26,986 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2023-02-07 14:13:26,986 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:26,987 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:26,989 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],DEPARTURES[26,13],OPERATIONS[29,13],TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19],FLIGHTS[17,10],FLIGHTS[-1,-1],FLIGHTS[-1,-1],ARRIVES[27,13] C: TOTAL_OPERATIONS[37,19],TOTAL_OPERATIONS[31,19] R: TOTAL_OPERATIONS[37,19]\n",
      "2023-02-07 14:13:26,998 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1252471141_0001_r_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:27,001 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 6 / 6 copied.\n",
      "2023-02-07 14:13:27,001 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1252471141_0001_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:27,006 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1252471141_0001_r_000000_0' to file:/tmp/temp-2041046484/tmp-2138365652\n",
      "2023-02-07 14:13:27,007 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:27,008 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1252471141_0001_r_000000_0' done.\n",
      "2023-02-07 14:13:27,008 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1252471141_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144216490\n",
      "\t\tFILE: Number of bytes written=650035\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=70\n",
      "\t\tReduce shuffle bytes=7256\n",
      "\t\tReduce input records=420\n",
      "\t\tReduce output records=70\n",
      "\t\tSpilled Records=420\n",
      "\t\tShuffled Maps =6\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=6\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:27,008 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1252471141_0001_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:27,008 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2023-02-07 14:13:27,130 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 14% complete\n",
      "2023-02-07 14:13:27,132 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,155 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,156 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2023-02-07 14:13:27,157 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,192 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:13:27,193 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:13:27,194 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:13:27,194 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2023-02-07 14:13:27,195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=1152\n",
      "2023-02-07 14:13:27,196 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:13:27,198 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2023-02-07 14:13:27,225 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:13:27,227 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,233 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:13:27,241 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:27,241 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:27,241 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:27,245 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2023-02-07 14:13:27,254 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1435746518_0002\n",
      "2023-02-07 14:13:27,254 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2023-02-07 14:13:27,331 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:13:27,332 [Thread-20] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:13:27,338 [Thread-20] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:13:27,338 [Thread-20] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:13:27,338 [Thread-20] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:13:27,338 [Thread-20] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,338 [Thread-20] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,338 [Thread-20] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:13:27,347 [Thread-20] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:13:27,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1435746518_0002_m_000000_0\n",
      "2023-02-07 14:13:27,355 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,355 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,356 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:27,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1152\n",
      "Input split[0]:\n",
      "   Length = 1152\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:27,366 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-2041046484/tmp-2138365652/part-r-00000:0+1152\n",
      "2023-02-07 14:13:27,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:27,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:27,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:27,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:27,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:27,386 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:27,393 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:27,393 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:27,394 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:27,398 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:27,398 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:27,398 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:27,398 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1464; bufvoid = 104857600\n",
      "2023-02-07 14:13:27,398 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214120(104856480); length = 277/6553600\n",
      "2023-02-07 14:13:27,404 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:27,408 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1435746518_0002_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:27,409 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:27,410 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1435746518_0002_m_000000_0' done.\n",
      "2023-02-07 14:13:27,410 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1435746518_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144218102\n",
      "\t\tFILE: Number of bytes written=1267964\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=70\n",
      "\t\tMap output records=70\n",
      "\t\tMap output bytes=1464\n",
      "\t\tMap output materialized bytes=1610\n",
      "\t\tInput split bytes=380\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:27,410 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1435746518_0002_m_000000_0\n",
      "2023-02-07 14:13:27,410 [Thread-20] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:27,425 [Thread-20] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:27,425 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1435746518_0002_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:27,437 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,438 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,442 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:27,442 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@388f9432\n",
      "2023-02-07 14:13:27,442 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,444 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:27,449 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1435746518_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2023-02-07 14:13:27,453 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1435746518_0002_m_000000_0 decomp: 1606 len: 1610 to MEMORY\n",
      "2023-02-07 14:13:27,454 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1606 bytes from map-output for attempt_local1435746518_0002_m_000000_0\n",
      "2023-02-07 14:13:27,454 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1606, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1606\n",
      "2023-02-07 14:13:27,457 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:27,458 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:27,458 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:27,459 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:27,460 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1590 bytes\n",
      "2023-02-07 14:13:27,461 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1606 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:27,461 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1610 bytes from disk\n",
      "2023-02-07 14:13:27,461 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:27,461 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:27,462 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1590 bytes\n",
      "2023-02-07 14:13:27,463 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:27,466 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,466 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,468 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:27,468 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:27,471 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:27,479 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1435746518_0002_r_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:27,481 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:27,481 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1435746518_0002_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:27,486 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1435746518_0002_r_000000_0' to file:/tmp/temp-2041046484/tmp425599012\n",
      "2023-02-07 14:13:27,487 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:27,487 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1435746518_0002_r_000000_0' done.\n",
      "2023-02-07 14:13:27,488 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1435746518_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144221354\n",
      "\t\tFILE: Number of bytes written=1269637\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=1610\n",
      "\t\tReduce input records=70\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=70\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:27,488 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1435746518_0002_r_000000_0\n",
      "2023-02-07 14:13:27,488 [Thread-20] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2023-02-07 14:13:27,634 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1435746518_0002\n",
      "2023-02-07 14:13:27,634 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOTAL_OPERATIONS\n",
      "2023-02-07 14:13:27,634 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:27,635 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 28% complete\n",
      "2023-02-07 14:13:27,636 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,638 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,641 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,645 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:13:27,646 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:13:27,646 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:13:27,646 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:13:27,650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:27,719 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:13:27,721 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,726 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:13:27,728 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:27,729 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:27,729 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:27,730 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2023-02-07 14:13:27,754 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2017498330_0003\n",
      "2023-02-07 14:13:27,754 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2023-02-07 14:13:27,838 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:13:27,841 [Thread-27] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:13:27,846 [Thread-27] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:13:27,847 [Thread-27] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:13:27,847 [Thread-27] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:13:27,847 [Thread-27] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,847 [Thread-27] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,848 [Thread-27] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:13:27,862 [Thread-27] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:13:27,866 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2017498330_0003_m_000000_0\n",
      "2023-02-07 14:13:27,874 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,876 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:27,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1152\n",
      "Input split[0]:\n",
      "   Length = 1152\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:27,879 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-2041046484/tmp-2138365652/part-r-00000:0+1152\n",
      "2023-02-07 14:13:27,914 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:27,915 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:27,915 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:27,915 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:27,915 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:27,917 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:27,920 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:27,920 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:27,921 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:27,925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:27,925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:27,925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:27,925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1470; bufvoid = 104857600\n",
      "2023-02-07 14:13:27,925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214120(104856480); length = 277/6553600\n",
      "2023-02-07 14:13:27,935 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:27,937 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2017498330_0003_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:27,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:27,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2017498330_0003_m_000000_0' done.\n",
      "2023-02-07 14:13:27,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local2017498330_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144222966\n",
      "\t\tFILE: Number of bytes written=1891476\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=70\n",
      "\t\tMap output records=70\n",
      "\t\tMap output bytes=1470\n",
      "\t\tMap output materialized bytes=121\n",
      "\t\tInput split bytes=380\n",
      "\t\tCombine input records=70\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=18\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:27,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2017498330_0003_m_000000_0\n",
      "2023-02-07 14:13:27,938 [Thread-27] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:27,940 [Thread-27] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:27,941 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2017498330_0003_r_000000_0\n",
      "2023-02-07 14:13:27,948 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,948 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,949 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:27,949 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@373379bf\n",
      "2023-02-07 14:13:27,949 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:27,950 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:27,954 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2017498330_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2023-02-07 14:13:27,959 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local2017498330_0003_m_000000_0 decomp: 117 len: 121 to MEMORY\n",
      "2023-02-07 14:13:27,960 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 117 bytes from map-output for attempt_local2017498330_0003_m_000000_0\n",
      "2023-02-07 14:13:27,960 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 117, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->117\n",
      "2023-02-07 14:13:27,962 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:27,963 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:27,964 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:27,965 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:27,965 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 105 bytes\n",
      "2023-02-07 14:13:27,966 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 117 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:27,966 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 121 bytes from disk\n",
      "2023-02-07 14:13:27,966 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:27,966 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:27,967 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 105 bytes\n",
      "2023-02-07 14:13:27,967 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:27,971 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:27,971 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:27,977 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:27,977 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:27,978 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:27,979 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2017498330_0003_r_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:27,981 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:27,981 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local2017498330_0003_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:27,983 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2017498330_0003_r_000000_0' to file:/tmp/temp-2041046484/tmp-472335232\n",
      "2023-02-07 14:13:27,984 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:27,984 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2017498330_0003_r_000000_0' done.\n",
      "2023-02-07 14:13:27,984 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local2017498330_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144223240\n",
      "\t\tFILE: Number of bytes written=1891694\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=121\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:27,984 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2017498330_0003_r_000000_0\n",
      "2023-02-07 14:13:27,984 [Thread-27] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2023-02-07 14:13:28,140 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local2017498330_0003\n",
      "2023-02-07 14:13:28,141 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOTAL_OPERATIONS\n",
      "2023-02-07 14:13:28,141 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:28,142 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 42% complete\n",
      "2023-02-07 14:13:28,144 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,145 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,147 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,152 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:13:28,152 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:13:28,152 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:13:28,152 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:13:28,175 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2023-02-07 14:13:28,205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:13:28,206 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,210 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:13:28,215 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:28,216 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:28,216 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:28,217 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2023-02-07 14:13:28,227 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local868288986_0004\n",
      "2023-02-07 14:13:28,227 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:28,291 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:13:28,293 [Thread-34] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:13:28,297 [Thread-34] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:13:28,297 [Thread-34] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:13:28,297 [Thread-34] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:13:28,298 [Thread-34] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:28,298 [Thread-34] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:28,298 [Thread-34] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:13:28,302 [Thread-34] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:13:28,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local868288986_0004_m_000000_0\n",
      "2023-02-07 14:13:28,316 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:28,316 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:28,316 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:28,317 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 85\n",
      "Input split[0]:\n",
      "   Length = 85\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:28,319 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-2041046484/tmp-472335232/part-r-00000:0+85\n",
      "2023-02-07 14:13:28,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:28,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:28,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:28,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:28,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:28,334 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:28,337 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:28,338 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:28,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:28,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:28,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:28,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:28,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 105; bufvoid = 104857600\n",
      "2023-02-07 14:13:28,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2023-02-07 14:13:28,343 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:28,345 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local868288986_0004_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:28,346 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:28,346 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local868288986_0004_m_000000_0' done.\n",
      "2023-02-07 14:13:28,346 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local868288986_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144223774\n",
      "\t\tFILE: Number of bytes written=2499205\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=105\n",
      "\t\tMap output materialized bytes=121\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:28,346 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local868288986_0004_m_000000_0\n",
      "2023-02-07 14:13:28,346 [Thread-34] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:28,347 [Thread-34] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:28,347 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local868288986_0004_r_000000_0\n",
      "2023-02-07 14:13:28,355 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:28,355 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:28,359 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:28,359 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29649aa1\n",
      "2023-02-07 14:13:28,359 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,360 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:28,364 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local868288986_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2023-02-07 14:13:28,374 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local868288986_0004_m_000000_0 decomp: 117 len: 121 to MEMORY\n",
      "2023-02-07 14:13:28,375 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 117 bytes from map-output for attempt_local868288986_0004_m_000000_0\n",
      "2023-02-07 14:13:28,375 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 117, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->117\n",
      "2023-02-07 14:13:28,376 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:28,377 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:28,377 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:28,379 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:28,379 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 105 bytes\n",
      "2023-02-07 14:13:28,379 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 117 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:28,380 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 121 bytes from disk\n",
      "2023-02-07 14:13:28,380 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:28,380 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:28,380 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 105 bytes\n",
      "2023-02-07 14:13:28,380 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:28,382 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:28,382 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:28,384 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:28,384 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:28,385 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:28,386 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local868288986_0004_r_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:28,388 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:28,388 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local868288986_0004_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:28,393 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local868288986_0004_r_000000_0' to file:/tmp/temp-2041046484/tmp-1077555946\n",
      "2023-02-07 14:13:28,394 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:28,394 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local868288986_0004_r_000000_0' done.\n",
      "2023-02-07 14:13:28,394 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local868288986_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144224048\n",
      "\t\tFILE: Number of bytes written=2499423\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=121\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=761790464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:28,394 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local868288986_0004_r_000000_0\n",
      "2023-02-07 14:13:28,394 [Thread-34] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:28,592 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local868288986_0004\n",
      "2023-02-07 14:13:28,592 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOTAL_OPERATIONS\n",
      "2023-02-07 14:13:28,592 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOTAL_OPERATIONS[40,19] C:  R: \n",
      "2023-02-07 14:13:28,593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 57% complete\n",
      "2023-02-07 14:13:28,594 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,595 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,596 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,601 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:13:28,601 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:13:28,602 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:13:28,602 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2023-02-07 14:13:28,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=16393\n",
      "2023-02-07 14:13:28,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:13:28,612 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2023-02-07 14:13:28,644 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:13:28,646 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:28,649 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:13:28,656 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:28,657 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:28,657 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:28,659 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:28,659 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:28,659 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:28,660 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2023-02-07 14:13:28,668 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local167550179_0005\n",
      "2023-02-07 14:13:28,668 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2023-02-07 14:13:28,745 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:13:28,746 [Thread-41] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:13:28,750 [Thread-41] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:13:28,750 [Thread-41] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:13:28,750 [Thread-41] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:13:28,750 [Thread-41] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:28,750 [Thread-41] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:28,751 [Thread-41] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:13:28,755 [Thread-41] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:13:28,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local167550179_0005_m_000000_0\n",
      "2023-02-07 14:13:28,766 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:28,766 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:28,766 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:28,767 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 16308\n",
      "Input split[0]:\n",
      "   Length = 16308\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:28,769 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/airports.csv:0+16308\n",
      "2023-02-07 14:13:28,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:28,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:28,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:28,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:28,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:28,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:28,965 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:28,965 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:28,967 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[46,23],AIRPORTS[11,11],AIRPORTS[-1,-1],TOP_TOTAL_OPERATIONS[46,23] C:  R: TOP_TOTAL_OPERATIONS[51,23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:29,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:29,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:29,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:29,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 13459; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212940(104851760); length = 1457/6553600\n",
      "2023-02-07 14:13:29,010 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:29,022 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local167550179_0005_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:29,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:29,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local167550179_0005_m_000000_0' done.\n",
      "2023-02-07 14:13:29,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local167550179_0005_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144241172\n",
      "\t\tFILE: Number of bytes written=3127151\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=365\n",
      "\t\tMap output records=365\n",
      "\t\tMap output bytes=13459\n",
      "\t\tMap output materialized bytes=14195\n",
      "\t\tInput split bytes=361\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=365\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=156\n",
      "\t\tTotal committed heap usage (bytes)=575668224\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_airports.csv=365\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:29,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local167550179_0005_m_000000_0\n",
      "2023-02-07 14:13:29,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local167550179_0005_m_000001_0\n",
      "2023-02-07 14:13:29,036 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,036 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,036 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:29,038 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 85\n",
      "Input split[0]:\n",
      "   Length = 85\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:29,041 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-2041046484/tmp-1077555946/part-r-00000:0+85\n",
      "2023-02-07 14:13:29,057 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:29,057 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:29,057 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:29,057 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,057 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:29,059 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:29,061 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:29,061 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,063 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[46,23],AIRPORTS[11,11],AIRPORTS[-1,-1],TOP_TOTAL_OPERATIONS[46,23] C:  R: TOP_TOTAL_OPERATIONS[51,23]\n",
      "2023-02-07 14:13:29,064 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:29,064 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:29,064 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:29,064 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 80; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,064 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2023-02-07 14:13:29,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:29,068 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local167550179_0005_m_000001_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:29,069 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:29,069 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local167550179_0005_m_000001_0' done.\n",
      "2023-02-07 14:13:29,069 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local167550179_0005_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144242037\n",
      "\t\tFILE: Number of bytes written=3127279\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=80\n",
      "\t\tMap output materialized bytes=96\n",
      "\t\tInput split bytes=380\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=575668224\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_tmp-1077555946=5\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:29,069 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local167550179_0005_m_000001_0\n",
      "2023-02-07 14:13:29,069 [Thread-41] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:29,070 [Thread-41] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:29,073 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local167550179_0005_r_000000_0\n",
      "2023-02-07 14:13:29,080 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,080 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,081 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:29,082 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59c0c9e9\n",
      "2023-02-07 14:13:29,082 [pool-18-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,083 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:29,084 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local167550179_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2023-02-07 14:13:29,085 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#5 about to shuffle output of map attempt_local167550179_0005_m_000000_0 decomp: 14191 len: 14195 to MEMORY\n",
      "2023-02-07 14:13:29,086 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 14191 bytes from map-output for attempt_local167550179_0005_m_000000_0\n",
      "2023-02-07 14:13:29,086 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 14191, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14191\n",
      "2023-02-07 14:13:29,087 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#5 about to shuffle output of map attempt_local167550179_0005_m_000001_0 decomp: 92 len: 96 to MEMORY\n",
      "2023-02-07 14:13:29,087 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 92 bytes from map-output for attempt_local167550179_0005_m_000001_0\n",
      "2023-02-07 14:13:29,087 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 92, inMemoryMapOutputs.size() -> 2, commitMemory -> 14191, usedMemory ->14283\n",
      "2023-02-07 14:13:29,087 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:29,088 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2023-02-07 14:13:29,088 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:29,089 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 2 sorted segments\n",
      "2023-02-07 14:13:29,089 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 14263 bytes\n",
      "2023-02-07 14:13:29,092 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 14283 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:29,093 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 14285 bytes from disk\n",
      "2023-02-07 14:13:29,093 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:29,093 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:29,093 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 14271 bytes\n",
      "2023-02-07 14:13:29,093 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2023-02-07 14:13:29,095 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,095 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,096 [pool-18-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:29,096 [pool-18-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,098 [pool-18-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[46,23],AIRPORTS[11,11],AIRPORTS[-1,-1],TOP_TOTAL_OPERATIONS[46,23] C:  R: TOP_TOTAL_OPERATIONS[51,23]\n",
      "2023-02-07 14:13:29,108 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local167550179_0005_r_000000_0 is done. And is in the process of committing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:29,110 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2023-02-07 14:13:29,110 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local167550179_0005_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:29,112 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local167550179_0005_r_000000_0' to file:/tmp/temp-2041046484/tmp603311600\n",
      "2023-02-07 14:13:29,114 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:29,114 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local167550179_0005_r_000000_0' done.\n",
      "2023-02-07 14:13:29,115 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local167550179_0005_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144270677\n",
      "\t\tFILE: Number of bytes written=3141780\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=365\n",
      "\t\tReduce shuffle bytes=14291\n",
      "\t\tReduce input records=370\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=370\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=575668224\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:29,115 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local167550179_0005_r_000000_0\n",
      "2023-02-07 14:13:29,115 [Thread-41] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2023-02-07 14:13:29,145 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local167550179_0005\n",
      "2023-02-07 14:13:29,145 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases AIRPORTS,TOP_TOTAL_OPERATIONS\n",
      "2023-02-07 14:13:29,145 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOP_TOTAL_OPERATIONS[46,23],AIRPORTS[11,11],AIRPORTS[-1,-1],TOP_TOTAL_OPERATIONS[46,23] C:  R: TOP_TOTAL_OPERATIONS[51,23]\n",
      "2023-02-07 14:13:29,146 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 71% complete\n",
      "2023-02-07 14:13:29,147 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,148 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,149 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,155 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:13:29,158 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:13:29,158 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:13:29,158 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2023-02-07 14:13:29,159 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=204\n",
      "2023-02-07 14:13:29,159 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:13:29,161 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2023-02-07 14:13:29,170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:13:29,172 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,243 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:13:29,246 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:29,246 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:29,246 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:29,248 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2023-02-07 14:13:29,255 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local285307142_0006\n",
      "2023-02-07 14:13:29,255 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2023-02-07 14:13:29,321 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:13:29,322 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:13:29,326 [Thread-49] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:13:29,326 [Thread-49] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:13:29,326 [Thread-49] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:13:29,326 [Thread-49] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,326 [Thread-49] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,326 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:13:29,329 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:13:29,329 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local285307142_0006_m_000000_0\n",
      "2023-02-07 14:13:29,335 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,335 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,335 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:29,336 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 204\n",
      "Input split[0]:\n",
      "   Length = 204\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:29,338 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-2041046484/tmp603311600/part-r-00000:0+204\n",
      "2023-02-07 14:13:29,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:29,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:29,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:29,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:29,350 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:29,351 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:29,351 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[54,23] C:  R: \n",
      "2023-02-07 14:13:29,353 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:29,353 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:29,353 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:29,353 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,353 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2023-02-07 14:13:29,354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:29,362 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local285307142_0006_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:29,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:29,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local285307142_0006_m_000000_0' done.\n",
      "2023-02-07 14:13:29,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local285307142_0006_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144271330\n",
      "\t\tFILE: Number of bytes written=3756098\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=110\n",
      "\t\tMap output materialized bytes=126\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=655360000\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:29,365 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local285307142_0006_m_000000_0\n",
      "2023-02-07 14:13:29,365 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:29,366 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:29,366 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local285307142_0006_r_000000_0\n",
      "2023-02-07 14:13:29,371 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,371 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,373 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:29,373 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@43220401\n",
      "2023-02-07 14:13:29,373 [pool-21-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:29,374 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:29,376 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local285307142_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2023-02-07 14:13:29,377 [localfetcher#6] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#6 about to shuffle output of map attempt_local285307142_0006_m_000000_0 decomp: 122 len: 126 to MEMORY\n",
      "2023-02-07 14:13:29,377 [localfetcher#6] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 122 bytes from map-output for attempt_local285307142_0006_m_000000_0\n",
      "2023-02-07 14:13:29,377 [localfetcher#6] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->122\n",
      "2023-02-07 14:13:29,378 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:29,379 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:29,379 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:29,380 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:29,381 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 106 bytes\n",
      "2023-02-07 14:13:29,381 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 122 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:29,381 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 126 bytes from disk\n",
      "2023-02-07 14:13:29,381 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:29,382 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:29,382 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 106 bytes\n",
      "2023-02-07 14:13:29,382 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:29,384 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,384 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,386 [pool-21-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:29,386 [pool-21-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,389 [pool-21-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[54,23] C:  R: \n",
      "2023-02-07 14:13:29,391 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local285307142_0006_r_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:29,393 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:29,393 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local285307142_0006_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:29,395 [pool-21-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local285307142_0006_r_000000_0' to file:/tmp/temp-2041046484/tmp2070859647\n",
      "2023-02-07 14:13:29,396 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:29,396 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local285307142_0006_r_000000_0' done.\n",
      "2023-02-07 14:13:29,396 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local285307142_0006_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144271614\n",
      "\t\tFILE: Number of bytes written=3756289\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=126\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=655360000\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:29,396 [pool-21-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local285307142_0006_r_000000_0\n",
      "2023-02-07 14:13:29,396 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2023-02-07 14:13:29,522 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local285307142_0006\n",
      "2023-02-07 14:13:29,522 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOP_TOTAL_OPERATIONS\n",
      "2023-02-07 14:13:29,522 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOP_TOTAL_OPERATIONS[54,23] C:  R: \n",
      "2023-02-07 14:13:29,523 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 85% complete\n",
      "2023-02-07 14:13:29,524 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,526 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,526 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,529 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2023-02-07 14:13:29,529 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2023-02-07 14:13:29,530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2023-02-07 14:13:29,530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2023-02-07 14:13:29,530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2023-02-07 14:13:29,544 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2023-02-07 14:13:29,546 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,550 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-02-07 14:13:29,552 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:29,552 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2023-02-07 14:13:29,552 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2023-02-07 14:13:29,554 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2023-02-07 14:13:29,561 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1757441329_0007\n",
      "2023-02-07 14:13:29,561 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:29,625 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2023-02-07 14:13:29,626 [Thread-56] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2023-02-07 14:13:29,630 [Thread-56] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2023-02-07 14:13:29,630 [Thread-56] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2023-02-07 14:13:29,630 [Thread-56] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2023-02-07 14:13:29,630 [Thread-56] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,630 [Thread-56] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,631 [Thread-56] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2023-02-07 14:13:29,636 [Thread-56] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2023-02-07 14:13:29,636 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1757441329_0007_m_000000_0\n",
      "2023-02-07 14:13:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:29,644 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 204\n",
      "Input split[0]:\n",
      "   Length = 204\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2023-02-07 14:13:29,646 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-2041046484/tmp603311600/part-r-00000:0+204\n",
      "2023-02-07 14:13:29,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2023-02-07 14:13:29,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2023-02-07 14:13:29,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2023-02-07 14:13:29,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,662 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2023-02-07 14:13:29,666 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2023-02-07 14:13:29,667 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:29,668 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[54,23] C:  R: \n",
      "2023-02-07 14:13:29,668 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2023-02-07 14:13:29,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2023-02-07 14:13:29,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2023-02-07 14:13:29,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 224; bufvoid = 104857600\n",
      "2023-02-07 14:13:29,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2023-02-07 14:13:29,670 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2023-02-07 14:13:29,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1757441329_0007_m_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:29,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2023-02-07 14:13:29,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1757441329_0007_m_000000_0' done.\n",
      "2023-02-07 14:13:29,672 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1757441329_0007_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144272267\n",
      "\t\tFILE: Number of bytes written=4367809\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=224\n",
      "\t\tMap output materialized bytes=240\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=3\n",
      "\t\tTotal committed heap usage (bytes)=648544256\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2023-02-07 14:13:29,672 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1757441329_0007_m_000000_0\n",
      "2023-02-07 14:13:29,672 [Thread-56] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2023-02-07 14:13:29,675 [Thread-56] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2023-02-07 14:13:29,675 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1757441329_0007_r_000000_0\n",
      "2023-02-07 14:13:29,681 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,681 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,682 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2023-02-07 14:13:29,682 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30d6339\n",
      "2023-02-07 14:13:29,682 [pool-24-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,683 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2023-02-07 14:13:29,694 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1757441329_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2023-02-07 14:13:29,696 [localfetcher#7] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#7 about to shuffle output of map attempt_local1757441329_0007_m_000000_0 decomp: 236 len: 240 to MEMORY\n",
      "2023-02-07 14:13:29,697 [localfetcher#7] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 236 bytes from map-output for attempt_local1757441329_0007_m_000000_0\n",
      "2023-02-07 14:13:29,697 [localfetcher#7] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 236, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->236\n",
      "2023-02-07 14:13:29,697 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2023-02-07 14:13:29,698 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:29,698 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2023-02-07 14:13:29,699 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:29,699 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 224 bytes\n",
      "2023-02-07 14:13:29,699 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 236 bytes to disk to satisfy reduce memory limit\n",
      "2023-02-07 14:13:29,700 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 240 bytes from disk\n",
      "2023-02-07 14:13:29,700 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2023-02-07 14:13:29,700 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2023-02-07 14:13:29,700 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 224 bytes\n",
      "2023-02-07 14:13:29,700 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:29,702 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2023-02-07 14:13:29,702 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2023-02-07 14:13:29,704 [pool-24-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2023-02-07 14:13:29,704 [pool-24-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,705 [pool-24-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: TOP_TOTAL_OPERATIONS[54,23] C:  R: \n",
      "2023-02-07 14:13:29,706 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1757441329_0007_r_000000_0 is done. And is in the process of committing\n",
      "2023-02-07 14:13:29,708 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2023-02-07 14:13:29,709 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1757441329_0007_r_000000_0 is allowed to commit now\n",
      "2023-02-07 14:13:29,713 [pool-24-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1757441329_0007_r_000000_0' to file:/tmp/temp-2041046484/tmp1595608667\n",
      "2023-02-07 14:13:29,714 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2023-02-07 14:13:29,714 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1757441329_0007_r_000000_0' done.\n",
      "2023-02-07 14:13:29,714 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1757441329_0007_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144272779\n",
      "\t\tFILE: Number of bytes written=4368265\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=240\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=648544256\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2023-02-07 14:13:29,714 [pool-24-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1757441329_0007_r_000000_0\n",
      "2023-02-07 14:13:29,715 [Thread-56] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 14:13:29,826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1757441329_0007\n",
      "2023-02-07 14:13:29,826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases TOP_TOTAL_OPERATIONS\n",
      "2023-02-07 14:13:29,826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: TOP_TOTAL_OPERATIONS[54,23] C:  R: \n",
      "2023-02-07 14:13:29,828 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,829 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,831 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,834 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2023-02-07 14:13:29,846 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2023-02-07 14:12:45\t2023-02-07 14:13:29\tHASH_JOIN,GROUP_BY,ORDER_BY,LIMIT,UNION\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1252471141_0001\t6\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tARRIVES,DEPARTURES,FLIGHTS,OPERATIONS,TOTAL_OPERATIONS\tGROUP_BY,COMBINER\t\n",
      "job_local1435746518_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOTAL_OPERATIONS\tSAMPLER\t\n",
      "job_local167550179_0005\t2\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tAIRPORTS,TOP_TOTAL_OPERATIONS\tHASH_JOIN\t\n",
      "job_local1757441329_0007\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOP_TOTAL_OPERATIONS\tORDER_BY\tfile:/tmp/temp-2041046484/tmp1595608667,\n",
      "job_local2017498330_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOTAL_OPERATIONS\tORDER_BY,COMBINER\t\n",
      "job_local285307142_0006\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOP_TOTAL_OPERATIONS\tSAMPLER\t\n",
      "job_local868288986_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tTOTAL_OPERATIONS\t\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/flights.csv\"\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/flights.csv\"\n",
      "Successfully read 365 records from: \"file:///media/notebooks/airports.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp-2041046484/tmp1595608667\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local1252471141_0001\t->\tjob_local1435746518_0002,\n",
      "job_local1435746518_0002\t->\tjob_local2017498330_0003,\n",
      "job_local2017498330_0003\t->\tjob_local868288986_0004,\n",
      "job_local868288986_0004\t->\tjob_local167550179_0005,\n",
      "job_local167550179_0005\t->\tjob_local285307142_0006,\n",
      "job_local285307142_0006\t->\tjob_local1757441329_0007,\n",
      "job_local1757441329_0007\n",
      "\n",
      "\n",
      "2023-02-07 14:13:29,847 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,848 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,850 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,855 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,859 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,861 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,863 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,867 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,868 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,870 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,871 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,872 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,874 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,875 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,876 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,879 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,880 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,881 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,884 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,885 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,887 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2023-02-07 14:13:29,889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2023-02-07 14:13:29,892 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2023-02-07 14:13:29,894 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2023-02-07 14:13:29,894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(Hartsfield-Jackson Atlanta International,297087)\n",
      "(Chicago O'Hare International,254536)\n",
      "(Los Angeles International,235988)\n",
      "(Dallas/Fort Worth International,208209)\n",
      "(Denver International,194178)\n",
      "2023-02-07 14:13:29,988 [main] INFO  org.apache.pig.Main - Pig script completed in 46 seconds and 919 milliseconds (46919 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en esencia con Pig pordemos hacer lo mismo que con Hive (lo contrario no es siempre cierto), con una sintaxis diferente. Particularmente a mí, en consultas complejas, me parece más fácil entender Pig Latin que HQL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
